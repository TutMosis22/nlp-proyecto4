{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "663939bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d55337",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adfd6712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\calag\\Desktop\\nlp-proyecto4\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n",
      "c:\\Users\\calag\\Desktop\\nlp-proyecto4\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\calag\\.cache\\huggingface\\hub\\models--distilbert-base-cased-distilled-squad. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from inference.pipelines import generate_text, answer_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f428b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a galaxy far far away, a number of other worlds in this galaxy came together. In the distant past, planets were located within galaxy clusters, but there is no one there yet.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"When you leave your planet, it will be far away. But when you leave your planet, it will be far away. But when you leave your planet, it will be far away. But when you leave your planet, it will be far away. But when you leave your planet, it will be far away. But when you leave your planet, it will be far away. But when you leave your planet, it will be far away. But when you leave your planet, it will be far away. But when you leave your planet, it will be far away. But when you leave your planet, it will be far away. But when you leave your planet, it will be far away. But when you leave your planet, it will be far away. But when you leave your planet, it will be far away. But when you leave your planet, it will be far away. But when you leave your planet, it will be far away. But when you leave your planet, it will be far away. But when you leave your planet, it will\n"
     ]
    }
   ],
   "source": [
    "#PRUEBA DE GENERACIÓN DE TEXTO\n",
    "prompt = \"Once upon a time in a galaxy far\"\n",
    "print(generate_text(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91ee4537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Universidad Nacional de Ingeniería se encuentra en Lima\n"
     ]
    }
   ],
   "source": [
    "#PRUEBA DE QA\n",
    "contexto = \"La Universidad Nacional de Ingeniería se encuentra en Lima, Perú.\"\n",
    "pregunta = \"¿Dónde está la UNI?\"\n",
    "print(answer_question(contexto, pregunta))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
